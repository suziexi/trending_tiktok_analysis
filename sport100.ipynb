{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uyBN1-iHPso"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/sports.zip'"
      ],
      "metadata": {
        "id": "Y197f8ocJJAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02VQAx04qzK_",
        "outputId": "95b774ad-d78c-43f3-cbce-1670f0f0f46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "data_dir = '../content' # directory\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + '/train') # train folder grab\n",
        "print(\"The length of the folder: \", len(classes)) # find how many folder\n",
        "print(classes) # disply the folder in a list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "cK9hTDKEH2S5",
        "outputId": "f5731271-12a1-4bc2-a0e9-b42b1224c508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'drive', 'sample_data']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1594257720d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../content'\u001b[0m \u001b[0;31m# directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train folder grab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The length of the folder: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# find how many folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# disply the folder in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../content/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = ImageFolder(data_dir + '/train', transform=ToTensor())\n",
        "dataset2 = ImageFolder(data_dir + '/valid', transform=ToTensor())"
      ],
      "metadata": {
        "id": "95hw0_xtKqns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset.classes))\n",
        "print(dataset.classes)"
      ],
      "metadata": {
        "id": "OrdUtBTbK7jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ],
      "metadata": {
        "id": "_wu3gTRzK_KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(img, label):\n",
        "    print(\"Label: \", dataset.classes[label], \"(\"+str(label)+\")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "show_image(*dataset[100])"
      ],
      "metadata": {
        "id": "eBr7hWLzLAxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);\n",
        "from torch.utils.data.dataset import random_split\n",
        "val_size = int(len(dataset)*0.2)\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = data.random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "uuk037-ALjtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 50\n",
        "train_dl = DataLoader(train_ds,\n",
        "                      batch_size,\n",
        "                      shuffle=True,\n",
        "                      num_workers=2,\n",
        "                      pin_memory= True\n",
        "                     )\n",
        "val_dl = DataLoader(val_ds,\n",
        "                    batch_size*2,\n",
        "                    num_workers=2,\n",
        "                    pin_memory=True\n",
        "                   )"
      ],
      "metadata": {
        "id": "p7lSK0DHLlTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch_image(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=10).permute(1, 2, 0))\n",
        "        break\n",
        "show_batch_image(train_dl)"
      ],
      "metadata": {
        "id": "-ndZX4FwLmI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "n754hPNlLtua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet152\n",
        "resnet152 = models.resnet152(pretrained=True)  # deprecated\n",
        "resnet152\n"
      ],
      "metadata": {
        "id": "eq5QIob3LwGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = nn.Linear(2048, len(dataset.classes))\n",
        "resnet152.fc = last_layer\n",
        "resnet152"
      ],
      "metadata": {
        "id": "6-6Ptu-4MRry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SportsCnnModel(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = resnet152\n",
        "      \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "metadata": {
        "id": "xYq0jFy9MY6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SportsCnnModel()\n",
        "model"
      ],
      "metadata": {
        "id": "HmPb6NkdMiuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dl:\n",
        "    print('images.shape:', images.shape)\n",
        "    out = model(images)\n",
        "    print('out.shape:', out.shape)\n",
        "    print('out[0]:', out[0])\n",
        "    break"
      ],
      "metadata": {
        "id": "MeCTG4ucMk4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "cavLUsKYMva5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "FxNxJBRNMw9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ],
      "metadata": {
        "id": "JVCu-VhMMycJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "HQ7Z8CQiM0yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(SportsCnnModel(), device)"
      ],
      "metadata": {
        "id": "HNRr9HxhM2Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, val_dl)"
      ],
      "metadata": {
        "id": "UgqXF_YiM3cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 8   \n",
        "opt_func = torch.optim.Adam\n",
        "#lr = 0.001\n",
        "lr = 0.01"
      ],
      "metadata": {
        "id": "wqwG6O1IPHXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJ_Sss36Qwgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ],
      "metadata": {
        "id": "9gPlmtFDPMul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');"
      ],
      "metadata": {
        "id": "0fBUTg3XQ_gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)"
      ],
      "metadata": {
        "id": "L6N1uAP7RNBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "VUklLWBz8evG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())"
      ],
      "metadata": {
        "id": "9HB8rbaUYZn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model):\n",
        "  # convert to a batch of 1\n",
        "  xb = to_device(img.unsqueeze(0), device)\n",
        "  # get predictions from model\n",
        "  yb = model(xb)\n",
        "  # pic index with highest probability\n",
        "  _, preds = torch.max(yb, dim=1)\n",
        "  # retrive the class label\n",
        "  return dataset.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "zIFTcOLPYa_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_dataset[0]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('label:', dataset.classes[label], ', predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "ZUdFyapZYtRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_dataset[111]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('label:', dataset.classes[label], ', predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "bzu3WTUxYz2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gluoncv"
      ],
      "metadata": {
        "id": "E20fpeEaR-Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install utilies "
      ],
      "metadata": {
        "id": "81O9FdjtSTYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gluoncv"
      ],
      "metadata": {
        "id": "pXFp3y1xSwfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mxnet "
      ],
      "metadata": {
        "id": "xlVUjgZ0TG-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, nd, image\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv import utils\n",
        "from gluoncv.model_zoo import get_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from gluoncv.utils import try_import_cv2\n",
        "\n",
        "transform_fn = transforms.Compose([\n",
        "    video.VideoCenterCrop(size=224),\n",
        "    video.VideoToTensor(),\n",
        "    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "c_-CfgYBTDSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model):\n",
        "  # convert to a batch of 1\n",
        "  xb = to_device(img.unsqueeze(0), device)\n",
        "  # get predictions from model\n",
        "  yb = model(xb)\n",
        "  # pic index with highest probability\n",
        "  _, preds = torch.max(yb, dim=1)\n",
        "  # retrive the class label\n",
        "  return dataset.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "b3_60v4vVPFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_fn = transforms.Compose([\n",
        "    video.VideoCenterCrop(size=224),\n",
        "    video.VideoToTensor(),\n",
        "    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "___WektfWZuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cpu() "
      ],
      "metadata": {
        "id": "RqMamMxvalmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mxnet "
      ],
      "metadata": {
        "id": "5_IoatxqcHlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, nd, image\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv import utils\n",
        "from gluoncv.model_zoo import get_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from gluoncv.utils import try_import_cv2\n",
        "\n",
        "\n",
        "object_model = get_model('resnet152_v1', pretrained = True)"
      ],
      "metadata": {
        "id": "6apUk1JUcRNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_model "
      ],
      "metadata": {
        "id": "aSCZ3cu-cxuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from pprint import pprint\n",
        "\n",
        "co_list = [] "
      ],
      "metadata": {
        "id": "G_DiJDvAc0P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow --upgrade"
      ],
      "metadata": {
        "id": "CUqknjvOfXhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "id": "L8m-gcXZftLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gluoncv "
      ],
      "metadata": {
        "id": "4Z3ozvkBhchy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gluoncv.utils import try_import_cv2\n",
        "from gluoncv import utils\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cv2 = try_import_cv2()\n",
        "\n",
        "\n",
        "url_list = []\n",
        "\n",
        "action_dic = {}  \n",
        "object_list = {}  \n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "for i in range(1,71):\n",
        "    url = 'https://github.com/suziexi/ucf101/blob/main/temp/' +str(i) + '.mp4?raw=true'+str(i)+'.mp4?raw=true'\n",
        "    url_list.append(url)\n",
        "\n",
        "for url in url_list:\n",
        "  video_fname = utils.download(url) \n",
        "\n",
        "  cap = cv2.VideoCapture(video_fname) \n",
        "  cnt = 0\n",
        "  video_frames = []\n",
        "  while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "      cnt += 1\n",
        "      if ret and cnt % 40 == 0:\n",
        "          video_frames.append(frame)\n",
        "      if not ret: break\n",
        "  cap.release()\n",
        "  act_list = []\n",
        "  print('We evenly extract %d frames from the video %s.' % (len(video_frames), video_fname))\n",
        "  if video_frames:\n",
        "    video_frames_transformed = transform_fn(video_frames)\n",
        "    final_pred = 0\n",
        "    obj_final_pred = 0  \n",
        "     \n",
        "    for _, frame_img in enumerate(video_frames_transformed):\n",
        "        yb = model(torch.Tensor(frame_img).unsqueeze(0)) \n",
        "        _, pred = torch.max(yb, dim=1)\n",
        "        obj_pred = object_model(nd.array(frame_img).expand_dims(axis=0))\n",
        "        obj_final_pred += obj_pred\n",
        "        if dataset.classes[pred[0].item()] not in act_list: \n",
        "          act_list.append(dataset.classes[pred[0].item()])\n",
        "\n",
        "          if dataset.classes[pred[0].item()] not in act_dic: \n",
        "            act_dic[dataset.classes[pred[0].item()]] = 1 \n",
        "          else: \n",
        "            act_dic[dataset.classes[pred[0].item()]] += 1 \n",
        "\n",
        "    print(act_list) \n",
        "    \n",
        "\n",
        "    obj_final_pred /= len(video_frames)\n",
        "\n",
        "    classes = object_model.classes \n",
        "    topK = 4\n",
        "    ind = nd.topk(obj_final_pred, k=topK)[0].astype('int')\n",
        "    \n",
        "    this_frame = []  \n",
        "    print('[Object Detection] The input video is classified to be')\n",
        "    for i in range(topK):\n",
        "        print('\\t[%s], with  probability %.3f.'%\n",
        "              (classes[ind[i].asscalar()], nd.softmax(obj_final_pred)[0][ind[i]].asscalar()))\n",
        "        if classes[ind[i].asscalar()] in object_list: \n",
        "          object_list[classes[ind[i].asscalar()] ] += nd.softmax(obj_final_pred)[0][ind[i]].asscalar()\n",
        "          this_frame.append(classes[ind[i].asscalar()])\n",
        "          \n",
        "        else: \n",
        "          object_list[classes[ind[i].asscalar()] ] = nd.softmax(obj_final_pred)[0][ind[i]].asscalar() \n",
        "          this_frame.append(classes[ind[i].asscalar()])\n",
        "        \n",
        "\n",
        "\n",
        "print(act_dic)"
      ],
      "metadata": {
        "id": "z8VYksVTVw2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code reference: https://www.kaggle.com/datasets/gpiosenka/sports-classification\n",
        "# https://www.kaggle.com/code/mahfuzraihan/sportsclassification-resnet50 "
      ],
      "metadata": {
        "id": "9DLb2bRGjDnm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}